{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "from camel_tools.utils import transliterate as tsl\n",
    "from camel_tools.utils import charmap as chmap\n",
    "import xml.etree.ElementTree as et\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.append('/Users/nurpeiis/Desktop/Capstone/hierarchical-did/utils')\n",
    "from data_process import DataProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Nasser's splits\n",
    "def get_sentences(filename):\n",
    "    sentences = []\n",
    "    trns = tsl.Transliterator(\n",
    "                chmap.CharMapper.builtin_mapper('bw2ar'))\n",
    "    with open('../../data_raw/lev_nasser/'+filename, 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for i in range(len(lines)):\n",
    "            if 'SENTENCE_ID' in lines[i]:\n",
    "                if 'SENTENCE_ID' in lines[i+1]:\n",
    "                    sentence = lines[i+1].replace(';;; SENTENCE_ID ', '')\n",
    "                    sentence = trns.transliterate(sentence)\n",
    "                    sentences.append(sentence)\n",
    "    df = pd.DataFrame(columns = ['original_sentence', 'dialect_country_id', 'dialect_region_id'])\n",
    "    df['original_sentence'] = sentences\n",
    "    df['dialect_country_id'] = 'ps'\n",
    "    df['dialect_region_id'] = 'levant'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir('../../data_raw/lev_nasser/') if file[-6:] =='magold']\n",
    "for file in files:\n",
    "    get_sentences(file).to_csv('../../data_raw/lev_nasser/'+file+'.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcess('../data_processed_splited/curras/', 'manual_search', 'web_mixed', 'https://link.springer.com/article/10.1007/s10579-016-9370-7#Tab1', 'curras', {},{},0, 'corpus', 'original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    dp.save_file(file+'.tsv', dp.preprocess('../../data_raw/lev_nasser/'+file+'.tsv', '', '', 1, 2, header=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.save_features('../datasets_splited_features.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data_raw/Curras-Arabic-NYH/Curras.all.txt') as file:\n",
    "    lines = [i for i in file.read().splitlines() if i != '']\n",
    "final = []\n",
    "ar_letters = charsets.AR_LETTERS_CHARSET\n",
    "reg=re.compile('^[{}]+$'.format(ar_letters))\n",
    "for l in lines:\n",
    "    word = l.split()\n",
    "    line = \"\"\n",
    "    for w in word:\n",
    "        if reg.match(w):\n",
    "            line += w + \" \"\n",
    "    line = line[:-1]\n",
    "    if line != '' and not ('on' in line):\n",
    "        final.append(line)\n",
    "    \n",
    "df = pd.DataFrame(final)\n",
    "df.to_csv('../../data_raw/Curras-Arabic-NYH/processed.tsv', sep='t', index=False, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
